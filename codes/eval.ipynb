{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaozhiming/anaconda3/envs/lucifer/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/yaozhiming/anaconda3/envs/lucifer/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, PretrainedConfig, PreTrainedModel\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset,load_from_disk\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from zhconv import convert\n",
    "\n",
    "SPECIAL_TOKENS = ['[unused0]', '[unused1]', '[unused2]']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path =  '/home/yaozhiming/NLP/tasks/zero-shot.jsonl'\n",
    "\n",
    "#读取测试数据\n",
    "with open(dataset_path, 'r') as validation:\n",
    "    val_datas = validation.readlines()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>qid</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>台湾</td>\n",
       "      <td>Q22502</td>\n",
       "      <td>89974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>台湾</td>\n",
       "      <td>Q865</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>台湾</td>\n",
       "      <td>Q137816</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>台湾</td>\n",
       "      <td>Q245107</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>台湾</td>\n",
       "      <td>Q32081</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360061</th>\n",
       "      <td>阿波罗登月飞行器</td>\n",
       "      <td>Q46611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360062</th>\n",
       "      <td>阿波罗号</td>\n",
       "      <td>Q430728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360063</th>\n",
       "      <td>高球场</td>\n",
       "      <td>Q1048525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360064</th>\n",
       "      <td>阿波罗祀祝节</td>\n",
       "      <td>Q1813885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360065</th>\n",
       "      <td>阿波罗和达佛涅</td>\n",
       "      <td>Q945850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360066 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            title       qid   freq\n",
       "0              台湾    Q22502  89974\n",
       "1              台湾      Q865    398\n",
       "2              台湾   Q137816    110\n",
       "3              台湾   Q245107     90\n",
       "4              台湾    Q32081     62\n",
       "...           ...       ...    ...\n",
       "2360061  阿波罗登月飞行器    Q46611      1\n",
       "2360062      阿波罗号   Q430728      1\n",
       "2360063       高球场  Q1048525      1\n",
       "2360064    阿波罗祀祝节  Q1813885      1\n",
       "2360065   阿波罗和达佛涅   Q945850      1\n",
       "\n",
       "[2360066 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#at base\n",
    "at_base = pd.read_csv('/home/yaozhiming/NLP/data/at-base.tsv',sep='\\t',names= ['title', 'qid', 'freq'])\n",
    "at_base['title'] = at_base['title'].fillna(\"\")\n",
    "at_base['title'] = at_base['title'].apply(to_simpified_chinese)\n",
    "at_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1106303/1106303 [03:19<00:00, 5556.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#knowledge data\n",
    "kb_path = \"/home/yaozhiming/NLP/data/kb.jsonl\"\n",
    "with open(kb_path, 'r') as f:\n",
    "    l = f.readlines()\n",
    "\n",
    "\n",
    "kn_data = []\n",
    "for line in tqdm.tqdm(l):\n",
    "    data = json.loads(line.strip(\"\\n\"))\n",
    "    kn_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>宇宙</td>\n",
       "      <td>宇宙是所有时间、空间与其包含的内容物所构成的统一体；它包含了行星、恆星、星系、星系际空间、次...</td>\n",
       "      <td>[[0.3392995894, 0.1768409908, -0.0198271517, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>地球</td>\n",
       "      <td>地球是太阳系中由内及外的第三颗行星，距离太阳149 597 890.7公里/1天文单位，是宇...</td>\n",
       "      <td>[[0.2487931252, 0.1893451214, -0.0190741345, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>生命</td>\n",
       "      <td>生命是一种特征，物质存在的一种活跃形式。目前对于生命的定义在学术界还无共识，较流行的定义是一...</td>\n",
       "      <td>[[0.3636945784, 0.2380280644, 0.0107873324, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>死亡</td>\n",
       "      <td>死亡（），是相对于生命体存在（存活）的生命现象，指维持一个生物存活的所有的永久终止。能够导致...</td>\n",
       "      <td>[[0.153353855, 0.1682929695, -0.1472070962, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>人</td>\n",
       "      <td>人在生物学上通常指智人（），偶尔也泛指人属的史前物种，为灵长目、人科的一部分，人属成员大致都...</td>\n",
       "      <td>[[0.2332355231, 0.1824601293, 0.0065428372, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106298</th>\n",
       "      <td>Q105978805</td>\n",
       "      <td>CHALLENGER</td>\n",
       "      <td>《CHALLENGER》是日本男子组合JO1的第3张单曲，将于2021年4月28日由发行。 ...</td>\n",
       "      <td>[[0.1082611158, 0.5486280918, -0.1542419493, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106299</th>\n",
       "      <td>Q105979347</td>\n",
       "      <td>The_Renaissance_(Super_Junior专辑)</td>\n",
       "      <td>《The Renaissance》是韩国演唱团体Super Junior的第十张正规专辑，于...</td>\n",
       "      <td>[[0.2598350942, 0.4277872443, -0.2423282266, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106300</th>\n",
       "      <td>Q105981916</td>\n",
       "      <td>华亭县_(隋朝)</td>\n",
       "      <td>华亭县，中国曾经设置的一个县，在今甘肃省华亭市。  Section::::沿革. Secti...</td>\n",
       "      <td>[[-0.0635062754, 0.1128137559, -0.3678101003, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106301</th>\n",
       "      <td>Q105983449</td>\n",
       "      <td>过江新娘</td>\n",
       "      <td>《过江新娘》（）是新加坡新传媒私人有限公司制作的关于越南新娘的电视剧。此剧由及徐彬领衔主演，...</td>\n",
       "      <td>[[0.1781165004, 0.2649869323, -0.3329152167, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106302</th>\n",
       "      <td>Q105985227</td>\n",
       "      <td>省_(行政区划)</td>\n",
       "      <td>省是多个国家使用的一级行政区单位名称。  中文中，“省”常用于翻译英文「province」一...</td>\n",
       "      <td>[[0.1191304252, 0.3205619752, -0.0131233558, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106303 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                qid                             title  \\\n",
       "0                Q1                                宇宙   \n",
       "1                Q2                                地球   \n",
       "2                Q3                                生命   \n",
       "3                Q4                                死亡   \n",
       "4                Q5                                 人   \n",
       "...             ...                               ...   \n",
       "1106298  Q105978805                        CHALLENGER   \n",
       "1106299  Q105979347  The_Renaissance_(Super_Junior专辑)   \n",
       "1106300  Q105981916                          华亭县_(隋朝)   \n",
       "1106301  Q105983449                              过江新娘   \n",
       "1106302  Q105985227                          省_(行政区划)   \n",
       "\n",
       "                                                      text  \\\n",
       "0        宇宙是所有时间、空间与其包含的内容物所构成的统一体；它包含了行星、恆星、星系、星系际空间、次...   \n",
       "1        地球是太阳系中由内及外的第三颗行星，距离太阳149 597 890.7公里/1天文单位，是宇...   \n",
       "2        生命是一种特征，物质存在的一种活跃形式。目前对于生命的定义在学术界还无共识，较流行的定义是一...   \n",
       "3        死亡（），是相对于生命体存在（存活）的生命现象，指维持一个生物存活的所有的永久终止。能够导致...   \n",
       "4        人在生物学上通常指智人（），偶尔也泛指人属的史前物种，为灵长目、人科的一部分，人属成员大致都...   \n",
       "...                                                    ...   \n",
       "1106298  《CHALLENGER》是日本男子组合JO1的第3张单曲，将于2021年4月28日由发行。 ...   \n",
       "1106299  《The Renaissance》是韩国演唱团体Super Junior的第十张正规专辑，于...   \n",
       "1106300  华亭县，中国曾经设置的一个县，在今甘肃省华亭市。  Section::::沿革. Secti...   \n",
       "1106301  《过江新娘》（）是新加坡新传媒私人有限公司制作的关于越南新娘的电视剧。此剧由及徐彬领衔主演，...   \n",
       "1106302  省是多个国家使用的一级行政区单位名称。  中文中，“省”常用于翻译英文「province」一...   \n",
       "\n",
       "                                                    vector  \n",
       "0        [[0.3392995894, 0.1768409908, -0.0198271517, -...  \n",
       "1        [[0.2487931252, 0.1893451214, -0.0190741345, -...  \n",
       "2        [[0.3636945784, 0.2380280644, 0.0107873324, -0...  \n",
       "3        [[0.153353855, 0.1682929695, -0.1472070962, 0....  \n",
       "4        [[0.2332355231, 0.1824601293, 0.0065428372, 0....  \n",
       "...                                                    ...  \n",
       "1106298  [[0.1082611158, 0.5486280918, -0.1542419493, 0...  \n",
       "1106299  [[0.2598350942, 0.4277872443, -0.2423282266, 0...  \n",
       "1106300  [[-0.0635062754, 0.1128137559, -0.3678101003, ...  \n",
       "1106301  [[0.1781165004, 0.2649869323, -0.3329152167, 0...  \n",
       "1106302  [[0.1191304252, 0.3205619752, -0.0131233558, -...  \n",
       "\n",
       "[1106303 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knowledge base\n",
    "def to_simpified_chinese(x):\n",
    "    x = re.sub(' +', '', x)\n",
    "    return convert(x, 'zh-cn')\n",
    "\n",
    "\n",
    "kb_df = pd.DataFrame(kn_data)\n",
    "kb_df['title'] = kb_df['title'].fillna(\"\")\n",
    "kb_df['title'] = kb_df['title'].apply(to_simpified_chinese)\n",
    "kb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBertConfig(PretrainedConfig):\n",
    "    model_type = 'dual_bert'\n",
    "    def __init__(self, **kwargs):\n",
    "        self.bert_model_name = kwargs.pop('bert_model_name', 'bert-base-chinese')\n",
    "        self.tokenizer_len = kwargs.pop('tokenizer_len', 21128)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "class DualBert(PreTrainedModel):\n",
    "    config_class = DualBertConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert1 = BertModel.from_pretrained(config.bert_model_name)\n",
    "        self.bert2 = BertModel.from_pretrained(config.bert_model_name)\n",
    "        self.bert1.resize_token_embeddings(config.tokenizer_len)\n",
    "        self.bert2.resize_token_embeddings(config.tokenizer_len)\n",
    "\n",
    "    def forward(self, input_text, candidate_text):\n",
    "        batch_cls1 = self.bert1(**input_text).last_hidden_state[:, 0, :]\n",
    "        batch_cls2 = self.bert2(**candidate_text).last_hidden_state[:, 0, :]\n",
    "        similarity_scores = batch_cls1.mm(batch_cls2.T)\n",
    "        return similarity_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hansel-eval-zs-0</td>\n",
       "      <td>[Q97300711, Q1579354, Q1579265, Q1579270, Q157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hansel-eval-zs-1</td>\n",
       "      <td>[Q11090848, Q105985227, Q1579238, Q1579397, Q1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hansel-eval-zs-2</td>\n",
       "      <td>[Q105985227, Q1579238, Q1579406, Q1579397, Q15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hansel-eval-zs-3</td>\n",
       "      <td>[Q97958559, Q105985227, Q1579367, Q1579270, Q1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hansel-eval-zs-4</td>\n",
       "      <td>[Q105985227, Q1579238, Q1579406, Q1579397, Q15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>hansel-eval-zs-4710</td>\n",
       "      <td>[Q9063180, Q105985227, Q1579354, Q1579265, Q15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>hansel-eval-zs-4711</td>\n",
       "      <td>[Q10552244, Q16502, Q47064, Q1579367, Q1579285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>hansel-eval-zs-4712</td>\n",
       "      <td>[Q24885548, Q637776, Q105985227, Q1579354, Q15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>hansel-eval-zs-4713</td>\n",
       "      <td>[Q105985227, Q1579238, Q1579406, Q1579397, Q15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>hansel-eval-zs-4714</td>\n",
       "      <td>[Q833, Q2735683, Q105985227, Q1579341, Q157926...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                          candidate\n",
       "0        hansel-eval-zs-0  [Q97300711, Q1579354, Q1579265, Q1579270, Q157...\n",
       "1        hansel-eval-zs-1  [Q11090848, Q105985227, Q1579238, Q1579397, Q1...\n",
       "2        hansel-eval-zs-2  [Q105985227, Q1579238, Q1579406, Q1579397, Q15...\n",
       "3        hansel-eval-zs-3  [Q97958559, Q105985227, Q1579367, Q1579270, Q1...\n",
       "4        hansel-eval-zs-4  [Q105985227, Q1579238, Q1579406, Q1579397, Q15...\n",
       "...                   ...                                                ...\n",
       "4710  hansel-eval-zs-4710  [Q9063180, Q105985227, Q1579354, Q1579265, Q15...\n",
       "4711  hansel-eval-zs-4711  [Q10552244, Q16502, Q47064, Q1579367, Q1579285...\n",
       "4712  hansel-eval-zs-4712  [Q24885548, Q637776, Q105985227, Q1579354, Q15...\n",
       "4713  hansel-eval-zs-4713  [Q105985227, Q1579238, Q1579406, Q1579397, Q15...\n",
       "4714  hansel-eval-zs-4714  [Q833, Q2735683, Q105985227, Q1579341, Q157926...\n",
       "\n",
       "[4715 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取bm25的dataframe\n",
    "with open(\"/home/yaozhiming/NLP/data/candidates.json\", 'r') as file:\n",
    "    l  = json.load(file)\n",
    "bm25_df = pd.DataFrame(l)\n",
    "bm25_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 21129. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 21129. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "100%|██████████| 4715/4715 [40:26<00:00,  1.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4715 3077 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test BM25 recall rate\n",
    "\n",
    "pretrained_path = \"/home/yaozhiming/NLP/results/\"\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_path)   \n",
    "config = DualBertConfig(bert_model_name = \"/home/yaozhiming/NLP/bert-base-chinese/\",tokenizer_len=len(tokenizer))\n",
    "model = DualBert.from_pretrained(pretrained_path,config=config)\n",
    "cnt = zero_qid = correct = 0\n",
    "\n",
    "\n",
    "\n",
    "def find_match_index(qid, data_base):\n",
    "    start = 0\n",
    "    end = len(data_base)-1\n",
    "    while start <= end:\n",
    "        id = int(qid[1:])\n",
    "        mid = start + (end-start)//2\n",
    "        search_id = int(data_base.iloc[mid]['qid'][1:])\n",
    "        if search_id == id:\n",
    "            return mid\n",
    "        elif search_id < id:\n",
    "            start = mid + 1\n",
    "        else:\n",
    "            end = mid - 1\n",
    "    return -1\n",
    "\n",
    "def get_score(QID):\n",
    "    index = find_match_index(QID, kb_df)\n",
    "    candidate_last_hidden_state = torch.tensor(kb_df.iloc[index]['vector'])\n",
    "    similarity_scores = torch.mm(input_last_hidden_state, candidate_last_hidden_state.T)\n",
    "    return similarity_scores\n",
    "\n",
    "for i in tqdm.tqdm(val_datas):\n",
    "    t0 = time.time()\n",
    "    val_data = json.loads(i)\n",
    "    \n",
    "    #at_base 候选\n",
    "    mention = to_simpified_chinese(val_data['mention'])\n",
    "    contains_keyword_base = np.vectorize(lambda x: mention in x)(at_base['title'])\n",
    "    QID_candidates_base = at_base[contains_keyword_base]['qid']\n",
    "    \n",
    "    #knowledge base候选\n",
    "    contains_keyword_kb = np.vectorize(lambda x: mention in x)(kb_df['title'])\n",
    "    QID_candidates_kb = kb_df[contains_keyword_kb]['qid']\n",
    "    \n",
    "    QID_candidates = list(QID_candidates_base) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #BM25候选\n",
    "    id = val_data['id']\n",
    "    contains_keyword_bm25 = np.vectorize(lambda x: id == x)(bm25_df['id'])\n",
    "    QID_candidates_bm25 = bm25_df[contains_keyword_bm25]['candidate']\n",
    "    if len(QID_candidates_bm25) != 0:\n",
    "        QID_candidates_bm25 = list(QID_candidates_bm25)[0]\n",
    "    else:\n",
    "        QID_candidates_bm25 = []\n",
    "    \n",
    "    #候选QID为at_base候选，bm25候选，kb候选的并集\n",
    "    QID_candidates = list(QID_candidates_base) + list(QID_candidates_bm25) + list(QID_candidates_kb)\n",
    "    QID_candidates = list(set(QID_candidates))\n",
    "    \n",
    "    gt_QID = val_data['gold_id']\n",
    "    \n",
    "    #无候选QID\n",
    "    if len(QID_candidates) == 0:\n",
    "        zero_qid += 1\n",
    "        # print(\"QID 0\")\n",
    "        continue\n",
    "        # QID_candidates = list(kb_df['qid'])\n",
    "    \n",
    "    score_lists = []\n",
    "    \n",
    "     #计算mention text的embedding\n",
    "    context_left = val_data['text'][:val_data['start']]\n",
    "    context_right = val_data['text'][val_data['end']:]\n",
    "    input_text = tokenizer.cls_token + context_left + SPECIAL_TOKENS[0] + val_data['mention'] + SPECIAL_TOKENS[1] + context_right + tokenizer.sep_token\n",
    "    input_encodings = tokenizer(input_text, return_tensors='pt', add_special_tokens=False, padding=True, max_length=128, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        input_outputs = model.bert1(**input_encodings) \n",
    "        input_last_hidden_state = input_outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    #计算相似度\n",
    "    for j in range(len(QID_candidates)):\n",
    "        QID = QID_candidates[j]\n",
    "        similarity_scores = get_score(QID)\n",
    "        score_lists.append(similarity_scores)\n",
    "    \n",
    "    #预测QID\n",
    "    ans_QID = QID_candidates[score_lists.index(max(score_lists))]\n",
    "    if ans_QID == gt_QID:\n",
    "        correct += 1\n",
    "    cnt += 1\n",
    "print(cnt, correct, zero_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6525980911983033"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = correct/cnt\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于提前存储\n",
    "import torch.nn as nn\n",
    "import os\n",
    "file = \"/home/yaozhiming/NLP/data/kb.jsonl\"\n",
    "\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "    \n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_path)   \n",
    "\n",
    "config = DualBertConfig(bert_model_name = \"/home/yaozhiming/NLP/bert-base-chinese/\",tokenizer_len=len(tokenizer))\n",
    "model = DualBert.from_pretrained(pretrained_path,config=config)\n",
    "model_b2 = model.bert2\n",
    "\n",
    "for index in tqdm.tqdm(range(len(kb_df))):\n",
    "    \n",
    "    candidate_text = tokenizer.cls_token + str(kb_df.iloc[index]['title']) + SPECIAL_TOKENS[2] + str(kb_df.iloc[index]['text']) + tokenizer.sep_token\n",
    "    candidate_encodings = tokenizer(candidate_text, return_tensors='pt', add_special_tokens=False, padding=True, max_length=128, truncation=True)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        candidate_outputs = model_b2(**candidate_encodings) \n",
    "        candidate_last_hidden_state = candidate_outputs.last_hidden_state[:, 0, :]\n",
    "    knowledge = kb_df.iloc[index]\n",
    "    knowledge['vector'] = candidate_last_hidden_state.numpy()\n",
    "    knowledge_str = knowledge.to_json(orient = 'columns', force_ascii=False)\n",
    "    with open(file, 'a') as fout:\n",
    "        fout.write(knowledge_str)\n",
    "        fout.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucifer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
